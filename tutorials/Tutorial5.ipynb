{"cells": [{"cell_type": "markdown", "id": "d57f5391-14c4-44c2-8ce6-daf5449fce12", "metadata": {}, "source": ["# Tutorial 5: RJMCMC with Eryn"], "outputs": []}, {"cell_type": "markdown", "id": "b4d47393-00cb-4c8a-88e2-f32afe03779a", "metadata": {}, "source": ["In the fifth tutorial, we will look at running Eryn when the underlying model is changing. This means we will be using Reversible-Jump MCMC, also referred to as trans-dimensional MCMC. In this tutorial, there will only be 2 tasks because RJMCMC is complicated and putting together an RJMCMC run takes time and effort. "], "outputs": []}, {"cell_type": "code", "execution_count": null, "id": "49a31f3e", "metadata": {}, "outputs": [], "source": ["# # if running in google colab\n", "# !pip install eryn lisaanalysistools chainconsumer"]}, {"cell_type": "code", "execution_count": 1, "id": "746a2a3a-ae79-4e34-80a9-d26b264f73cd", "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "from lisatools.utils.constants import *\n", "from copy import deepcopy  # can be useful"]}, {"cell_type": "markdown", "id": "b1a3e8f1-25c1-4b19-bd0e-41e015a477bd", "metadata": {}, "source": ["## Task 1: How many Gaussian pulses?"], "outputs": []}, {"cell_type": "markdown", "id": "6b1baa93-be57-4cb5-8afe-ed7eccdd95c4", "metadata": {}, "source": ["The first RJ problem we will look at is determining how many 2D Gaussian pulses exist in a noisy set of data. This is an example you can find in the more advanced Eryn tutorials. To keep this simple in the time we have alotted, we will use a proposal based on the prior distribution (this is the default). If you set `rj_moves=True` in the setup of `EnsembleSampler`, it will automatically generate RJ proposals from the prior. However, you must be careful when using multiple branches (model types) because this proposal, by default, always proposes to change each model in the sampler by 1 model count, either add or remove. \n", "\n", "Useful documentation:\n", "* [EnsembleSampler](https://mikekatz04.github.io/Eryn/html/user/ensemble.html#eryn.ensemble.EnsembleSampler)\n", "* [State](https://mikekatz04.github.io/Eryn/html/user/state.html#eryn.state.State)\n", "* [uniform_dist](https://mikekatz04.github.io/Eryn/html/user/prior.html#eryn.prior.uniform_dist)\n", "* [ProbDistContainer](https://mikekatz04.github.io/Eryn/html/user/prior.html#eryn.prior.ProbDistContainer)\n", "* [GaussianMove](https://mikekatz04.github.io/Eryn/html/user/moves.html#eryn.moves.GaussianMove)\n", "* [DistributionGenerateRJ](https://mikekatz04.github.io/Eryn/html/user/moves.html#eryn.moves.DistributionGenerateRJ)"], "outputs": []}, {"cell_type": "code", "execution_count": 2, "id": "da14458d-99f0-4763-a026-c6ab7e220329", "metadata": {}, "outputs": [], "source": ["from eryn.ensemble import EnsembleSampler\n", "from eryn.state import State\n", "from eryn.prior import ProbDistContainer, uniform_dist\n", "from eryn.moves import GaussianMove\n", "from eryn.backends import HDFBackend\n", "from chainconsumer import ChainConsumer, Chain"]}, {"cell_type": "markdown", "id": "27e7784f-2c66-41a4-8637-ddeda065b997", "metadata": {}, "source": ["We will do the initial setup for you. Here we are going to set the x and y dimensions of our 2D grid."], "outputs": []}, {"cell_type": "code", "execution_count": 3, "id": "bb48fc35-f300-4415-b010-393568776e44", "metadata": {}, "outputs": [], "source": ["num     = 100 # the number of step for each dimension\n", "lowlim  = -10 # Low limit on each axis\n", "highlim = 10  # high limit on each axis\n", "npulses = 10  # The # of injected pulses\n", "\n", "dx = (highlim - lowlim) / num # Get the discritization\n", "\n", "x, y = np.mgrid[lowlim:highlim:dx, lowlim:highlim:dx]  # Generate the grid"]}, {"cell_type": "markdown", "id": "41d3eda3-001e-446b-b1e8-910847d71573", "metadata": {}, "source": ["Now, we will draw initial parameters for each set of pules. Each pulse gets an amplitude, x, and y value."], "outputs": []}, {"cell_type": "code", "execution_count": 4, "id": "0e2e542f-7c7a-4721-b36a-a0e9dd182ab1", "metadata": {}, "outputs": [], "source": ["Amp    = np.random.uniform(.5, 2.0, size=(npulses)) # Draw an amplitude\n", "spread = .2  # Keep their spread as fixed for simplicity.\n", "sigma  = spread * np.diag(np.ones(2))\n", "\n", "edges = 2 # Utility parameter, in order to avoid having signals at the border of our data set\n", "\n", "# Draw the coordinates parameters\n", "# generates random x and y coordinates\n", "inj_coordinates = np.random.uniform(lowlim+edges, highlim-edges, size=(npulses, 2))\n", "\n", "# Gather all parameters here\n", "gauss_inj_params = np.concatenate([Amp[:, None], inj_coordinates], axis=1)\n", "\n", "print(' * Parameters injected: \\n\\n', np.matrix(gauss_inj_params))"]}, {"cell_type": "markdown", "id": "fedfd9e8-e603-40c5-a609-a80858312a5e", "metadata": {}, "source": ["We have also filled in the Gaussian function and Likelihood to avoid any issues. The next few cells give an idea of the injection data. "], "outputs": []}, {"cell_type": "code", "execution_count": 5, "id": "ba900fa7-b9e6-4bcc-bbfe-76293fe4931a", "metadata": {}, "outputs": [], "source": ["# First we compute some constant terms of the Gaussian models (reminder: we have assumed a fixed spread for each pulse)\n", "sigma_det = np.linalg.det(sigma)\n", "sigma_inv = np.linalg.inv(sigma)\n", "norm      = np.sqrt((2*np.pi)**2 * sigma_det)\n", "\n", "def gaussian(X, Y, a, b, c):\n", "    x = X[:,0]\n", "    y = Y[0,:]\n", "    # breakpoint()\n", "    A = np.exp(-((x[None, :] - b[:, None]) ** 2) / (2 * sigma[0,0]))\n", "    B = np.exp(-((y[None, :] - c[:, None]) ** 2) / (2 * sigma[1,1]))\n", "    # breakpoint()\n", "    C =  A[:, None, :] * B[:, :, None] # (np.expand_dims(A,axis=0) * np.expand_dims(np.transpose(B),axis=2))\n", "\n", "    return a[:, None, None] * C / norm\n", "\n", "def log_prob_fn(x1, X, Y, data, sig):\n", "\n", "    a = x1[:, 0]\n", "    b = x1[:, 1]\n", "    c = x1[:, 2]\n", "    n = num * num\n", "\n", "    template  = np.sum(gaussian(X, Y, a, b, c), axis=0)\n", "\n", "    llh = - 0.5 * ( np.sum(((template - data)) ** 2) )\n", "    llh *= 1/sig**2\n", "    llh += - n*np.log(sig) - .5 * n * np.log(2.*np.pi)\n", "    return llh"]}, {"cell_type": "code", "execution_count": 6, "id": "ce246130-602a-4432-8923-86695db82f94", "metadata": {}, "outputs": [], "source": ["noise = spread * np.random.randn( num, num ) # Draw the random points for the noise\n", "\n", "# Generate the data-set\n", "injection = np.zeros( (num, num) )\n", "injection = np.sum(gaussian(x, y, gauss_inj_params[:, 0], gauss_inj_params[:, 1], gauss_inj_params[:, 2]), axis=0)\n", "data = injection + noise\n"]}, {"cell_type": "code", "execution_count": 7, "id": "3e214f21-2aeb-4aad-9777-e5d770ba5043", "metadata": {"scrolled": true}, "outputs": [], "source": ["from matplotlib import cm\n", "\n", "plt.figure(figsize=(17,7))\n", "plt.subplot(121)\n", "cf = plt.contourf(y, x, injection, 10, cmap=cm.PuBu)\n", "plt.scatter(gauss_inj_params[:,1], gauss_inj_params[:,2], marker='x', color='#DC143C')\n", "plt.colorbar(cf)\n", "plt.xlabel(r'$x$')\n", "plt.ylabel(r'$y$')\n", "plt.subplot(122)\n", "cf = plt.contourf(y, x, data, 10, cmap=cm.PuBu)\n", "plt.scatter(gauss_inj_params[:,1], gauss_inj_params[:,2], marker='x', color='#DC143C')\n", "plt.xlabel(r'$x$')\n", "plt.ylabel(r'$y$')\n", "plt.colorbar(cf)\n", "plt.show()\n"]}, {"cell_type": "markdown", "id": "1af75866-67e9-4ec8-a332-3f2731720e9c", "metadata": {}, "source": ["Now that we have most of the initial setup. We now need to build our sampling run. Let's start by choosing settings and building base requirements: `ndims`, `nleaves_max`, `nleaves_min`, `branch_names`, `ntemps`, `nwalkers`."], "outputs": []}, {"cell_type": "code", "execution_count": null, "id": "5f61ce47-12e9-454b-b870-a32e7e136dbb", "metadata": {}, "outputs": [], "source": ["\n"]}, {"cell_type": "markdown", "id": "76231881-960f-42f7-939b-dde9a206d4db", "metadata": {}, "source": ["Now we will setup our prior function. Make sure you initialize your prior with the `ProbDistContainer` object from Eryn. \n", "* For the amplitude, a uniform prior from 0.5 to 2.0.\n", "* For x and y, uniform priors across the acceptable ranges."], "outputs": []}, {"cell_type": "code", "execution_count": null, "id": "3536f3f1-7e5b-4126-bea1-b1ba9063cf1f", "metadata": {}, "outputs": [], "source": ["\n"]}, {"cell_type": "markdown", "id": "bc5fe8e3-8eda-43a2-9d01-8411ccbbc324", "metadata": {}, "source": ["When using RJMCMC, we must input a value for `moves` in the `EnsembleSampler`. This is because the default proposal (Stretch proposal) does not work in varying dimensionality. We will keep this simple and use a Gaussian proposal centered on the current point. We recommend a diagonal covariance matrix with the same covariance for each parameter. There are many ways to do this. \n", "\n", "Useful Documentation:\n", "* [GaussianMove](https://mikekatz04.github.io/Eryn/html/user/moves.html#eryn.moves.GaussianMove)"], "outputs": []}, {"cell_type": "code", "execution_count": 10, "id": "45773272-c143-4370-9ce4-d89c02758da2", "metadata": {}, "outputs": [], "source": ["# imports \n", "from eryn.moves import GaussianMove"]}, {"cell_type": "code", "execution_count": null, "id": "dd7e6da2-163a-49be-b3ad-cc95a8cac03c", "metadata": {}, "outputs": [], "source": ["\n"]}, {"cell_type": "markdown", "id": "e6f75fe0-9a1c-4d8a-bf10-189ed7219207", "metadata": {}, "source": ["Now we will instantiate the `EnsembleSampler`. For the tempering, set `tempering_kwargs=dict(ntemps=ntemps)`. "], "outputs": []}, {"cell_type": "code", "execution_count": null, "id": "1c99324a-f8b3-4849-ac5d-b3ccacdb1bc9", "metadata": {}, "outputs": [], "source": ["\n"]}, {"cell_type": "markdown", "id": "1f92454d-dfa9-4cd0-9bbc-c2fd5d037f43", "metadata": {}, "source": ["With the sampler prepared, we just need to generate our starting points. There are also many choices for this. In RJMCMC, it is more complicated because of the model uncertainty. For this simplified example, we are going to start by drawing **1 Gaussian per walker** from the prior. It will add more as the goes. Your goal here is to produce a `coords` dictionary of shape `(ntemps, nwalkers, nleaves_max, ndim)`. You can sample every source in that `coords` array because we will direct to have **only one** leaf per walker with the `inds` dictionary. `inds` should be a boolean array of shape `(ntemps, nwalkers, nleaves_max)`. You then index this and set one value to True per walker. Fill these dictionaries into a `State` object."], "outputs": []}, {"cell_type": "code", "execution_count": null, "id": "d12d8b92-00a4-486b-b78c-00d51cfc335b", "metadata": {}, "outputs": [], "source": ["\n"]}, {"cell_type": "markdown", "id": "b6cf8c08-f8f1-4895-aa94-ce3c68302be0", "metadata": {}, "source": ["Now run the sampler. We recommend a good burn in."], "outputs": []}, {"cell_type": "code", "execution_count": null, "id": "ebcc1f04-5c6c-45fa-9cfd-0372906dc978", "metadata": {}, "outputs": [], "source": ["\n"]}, {"cell_type": "markdown", "id": "52e3a8d7-0f11-48a7-8e36-916a0aafbf85", "metadata": {}, "source": ["Now read out the number of leaves per walker in the cold chain using the `ensemble.backend`. You only need the `inds` array for this. Plot a histogram of number of pulses found in the cold chain. This is a posterior distribution on the model count. \n", "\n", "Useful Documentation:\n", "* [Backend](https://mikekatz04.github.io/Eryn/html/user/backend.html#eryn.backends.Backend)"], "outputs": []}, {"cell_type": "code", "execution_count": null, "id": "a75c8386-cd56-4dbd-85c4-ec1d98cfff78", "metadata": {}, "outputs": [], "source": ["\n"]}, {"cell_type": "markdown", "id": "93a195db-e627-4e28-88c9-a7c6ec992a14", "metadata": {}, "source": ["### Question:\n", "Is this what you expected? Does RJMCMC tell us what the \"right\" answer is? How do you think the noise effects this posterior plot? If we increase the noise, what type of changes do we expect and why?"], "outputs": []}, {"cell_type": "markdown", "id": "0614387c-0a0a-4d61-91ad-732b48f9c2f2", "metadata": {}, "source": ["Now we will look at the parameters of the recovered pulses to see how well we located the injected pulses. To do this, we are going to flatten all of samples from all leaf counts found, i.e. we will take every single source in the cold chain and plot all of these overlayed. **Hint**: use the `inds` array to your advantage here.\n", "\n", "We recommend using `pandas` and `chainconsumer` to do this, but you can do it anyway you like. "], "outputs": []}, {"cell_type": "code", "execution_count": 16, "id": "1091e026-e5e7-4a54-8b66-4ce56810999b", "metadata": {}, "outputs": [], "source": ["import pandas as pd"]}, {"cell_type": "code", "execution_count": null, "id": "e1155a08-237c-411a-92d1-11d8030cf577", "metadata": {}, "outputs": [], "source": ["\n"]}, {"cell_type": "markdown", "id": "a64c72c8-b5a0-4d65-9e87-c6707b33da05", "metadata": {}, "source": ["### Question:\n", "How did we do? Was it a success? Could there be improvements? "], "outputs": []}, {"cell_type": "markdown", "id": "9fe0c884-4951-426b-8f44-7c316a972112", "metadata": {}, "source": ["## Task 2: Model selection with RJMCMC"], "outputs": []}, {"cell_type": "markdown", "id": "0fd22e6b-f668-4f70-a973-34860e4a81eb", "metadata": {}, "source": ["In this task, you will use RJMCMC to do a direct model comparison. This will be the same model comparison used in Tutorial 3 comparing a Gaussian pulse with a Cauchy pulse. In tutorial 3, we used fixed-dimensional MCMC and thermodynamic integration to estimate the evidence of each model. Then we compared them to get the Bayes Factor. Using RJMCMC will produce a posterior distribution on the model selection index rather than a direct evidence for each model. The fraction of walkers that have highlighted one model over the other represents a proxy for the odds ratio. This is not strictly true when one model is much more favored than another. However, when model favorability is close, this direct computation is okay. \n", "\n", "For simplicity, we will consider the spread of the signal to be 1. Therefore, we are only fitting and comparing the amplitude and mean of the pulse. \n", "\n", "Once again, we will start by providing the functions for the Gaussian pulse, Cauchy pulse, and the Likelihood function. "], "outputs": []}, {"cell_type": "code", "execution_count": 18, "id": "cc46c36e-3b51-42be-b743-3c67ef3f104a", "metadata": {}, "outputs": [], "source": ["from scipy.stats import cauchy\n", "def gaussian_pulse(x, a, b):\n", "    f_x = a * np.exp(-((x - b) ** 2) / (2 * 1.0 ** 2))\n", "    return f_x\n", "\n", "def cauchy_pulse(x, a, b):\n", "    f_x = a * cauchy.pdf(x - b)\n", "    return f_x\n", "\n", "def log_like_fn(params, t, data, sigma, which_template):\n", "\n", "    pulse_gen = gaussian_pulse if which_template == \"gauss\" else cauchy_pulse\n", "    template = pulse_gen(t, *params)\n", "\n", "    ll = -0.5 * np.sum(((template - data) / sigma) ** 2, axis=-1)\n", "    return ll\n", "\n", "def log_like_wrap(params, *args):\n", "    # must be careful about how these models are read into the Likelihood function\n", "    # In this case, we will have one model with a single set of parameters \n", "    # and one model that is None\n", "    \n", "    assert len(params) == 2\n", "    if params[0] is not None:\n", "        assert params[1] is None\n", "        # gauss will be first set of params\n", "        args += (\"gauss\",)\n", "        ll = log_like_fn(params[0][0], *args)\n", "\n", "    else:\n", "        assert params[0] is None\n", "        # gauss will be first set of params\n", "        args += (\"cauchy\",)\n", "        ll = log_like_fn(params[1][0], *args)\n", "\n", "    return ll"]}, {"cell_type": "markdown", "id": "31088420-c5ca-463d-aa4f-b7b092c6a976", "metadata": {}, "source": ["We will inject the Gausian pulse and compare to the Cauchy pulse."], "outputs": []}, {"cell_type": "code", "execution_count": 19, "id": "08950f28-5c4a-4f31-b243-e07b838b856c", "metadata": {}, "outputs": [], "source": ["t_vals = np.linspace(-10.0, 10.0, 1000)\n", "sigma = 3.5\n", "amp_true = 4.0\n", "mean_true = 0.0\n", "true_data = gaussian_pulse(t_vals, amp_true, mean_true)\n", "data = true_data + np.random.randn(*t_vals.shape) * sigma\n", "cauchy_data = cauchy_pulse(t_vals, amp_true * 3, mean_true)\n", "plt.plot(t_vals, data, label=\"data\")\n", "plt.plot(t_vals, true_data, label=\"gauss\")\n", "plt.plot(t_vals, cauchy_data, label=\"cauchy\")\n", "plt.legend()\n", "# plt.plot(x_vals, np.exp(log_like_fn()))\n", "# plt.plot(x_vals, np.exp(log_like_gauss(x_vals)))"]}, {"cell_type": "markdown", "id": "f7a5ade3-815e-46b0-a6fd-2cf8cd67c079", "metadata": {}, "source": ["We will follow the same setup order as the last problem. Start with the basic declarations (`ntemps`, `ndims`, etc.). For this problem, the max leaves for both models should be 1 and the min leaves for both models should be 0. "], "outputs": []}, {"cell_type": "code", "execution_count": null, "id": "5ca9c8da-afa5-4e89-a8a0-7443ad2bd771", "metadata": {}, "outputs": [], "source": ["\n"]}, {"cell_type": "markdown", "id": "ebe4b667-21c1-4966-a5a6-a1cd7080ee35", "metadata": {}, "source": ["Now we will put together the priors for both models. The priors are identical really for the two models. The amplitude prior should span the injection values. The mean prior should span the domain of time."], "outputs": []}, {"cell_type": "code", "execution_count": null, "id": "2e9a2466-f4b1-4afb-9cd6-1395c55604fe", "metadata": {}, "outputs": [], "source": ["\n"]}, {"cell_type": "markdown", "id": "7a861513-24ef-468b-a401-b6031dde4275", "metadata": {}, "source": ["Now we will produce the same type of `GaussianMove` that we built earlier. We need to make sure that to provide a covariance for each model! So, it must be a dictionary with entries for both models. The entries can really be the same though. "], "outputs": []}, {"cell_type": "code", "execution_count": null, "id": "2e4f7105-d7bd-43b2-b42c-5cb0d8e53aa1", "metadata": {}, "outputs": [], "source": ["\n"]}, {"cell_type": "markdown", "id": "10f6515d-9703-4477-b176-ab7c0ecb7b2d", "metadata": {}, "source": ["Instantiate the `EnsembleSampler`."], "outputs": []}, {"cell_type": "code", "execution_count": null, "id": "a67d3b1a-6f6a-4c7e-8b9c-44769ea5935c", "metadata": {}, "outputs": [], "source": ["\n"]}, {"cell_type": "markdown", "id": "1b7aa6bf-1e76-4b54-8e08-26bf6ae31a35", "metadata": {}, "source": ["Generate start points. **Note**: this is very important. This test will only work if:\n", "* we have **2** models,\n", "* each model has max leaves of 1 and min leaves of 0,\n", "* and the starting points must all have **either** the Gaussian or Cauchy pulse, not both and not neither.\n", "\n", "In this setup, each proposal will propose to switch the model and draw from its prior. \n", "\n", "Generate your start point and use the `inds` array to tell the sampler that each walker has only one model instance. "], "outputs": []}, {"cell_type": "code", "execution_count": null, "id": "d537d351-a74e-4e0e-9fa6-479447f36c4e", "metadata": {}, "outputs": [], "source": ["\n"]}, {"cell_type": "markdown", "id": "cead0290-9d33-4280-8365-cd155dc05a4d", "metadata": {}, "source": ["Run the sampler with a burn-in."], "outputs": []}, {"cell_type": "code", "execution_count": null, "id": "b51ab6c5-8ee5-43e4-8e81-266c01232d86", "metadata": {"scrolled": true}, "outputs": [], "source": ["\n"]}, {"cell_type": "markdown", "id": "7ae074f8-1fc8-4b4e-b694-45f92a2121b9", "metadata": {}, "source": ["To find our posterior odds ratio, we need to get the fraction of cold-chain samples that exist in one of the two states. Calculate the odds ratio."], "outputs": []}, {"cell_type": "code", "execution_count": null, "id": "01df13a5-2c58-42ee-bee5-1b57c88433ed", "metadata": {}, "outputs": [], "source": ["\n"]}, {"cell_type": "markdown", "id": "a4d062aa-24a5-4404-8b79-634288dc49fe", "metadata": {}, "source": ["### Question:\n", "If we change the noise, what effect will this have on our results? What happens when one model is heavily favored so that the fraction is 1? Is this a proper estimate of the odds ratio? What could we do in this case where the initial odds ratio is 1 to actually estimate the odds ratio?"], "outputs": []}, {"cell_type": "code", "execution_count": null, "id": "361ce33d-5bea-476f-841e-aaf894b9c982", "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.12.1"}}, "nbformat": 4, "nbformat_minor": 5}